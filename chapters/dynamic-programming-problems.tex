\section{Dynamic Programming Problems}
\index{Dynamic Programming} \index{DP} \index{Recursion}

Dynamic programming (often shortened to "dp") is a method to break down certain problems into smaller sub-problems, very similar to recursion. It can be thought of as an optimization over regular recursion, where multiple calls with the same input only have to be evaluated once instead of multiple times.

Consider the problem of calculating the Fibonacci sequence\index{Fibonacci Sequence}. The Fibonacci sequence is the sequence $0,1,1,2,3,5,8,13,21,34,55,89,...$ where each value (other than the initial $0,1$) is the sum of the previous two (so $89 = 55 + 34$, $55 = 34 + 21$, $34 = 21 + 13$, and so on). This is a pretty intuitive example of recursion, like in:

\inputcpp{code/dp/fib_recursive.cpp}

Unfortunately, this results in a lot of repeated work. A call to \mintinline{cpp}{fibonacci(10)} will call \mintinline{cpp}{fibonacci(9)} and \mintinline{cpp}{fibonacci(8)}, where \mintinline{cpp}{fibonacci(9)} will also call \mintinline{cpp}{fibonacci(8)}, \mintinline{cpp}{fibonacci(7)} ends up getting called 3 times, \mintinline{cpp}{fibonacci(6)} gets called 5 times, and so on until \mintinline{cpp}{fibonacci(1)} ultimately gets called 56 times. There is a huge amount of work being done with these recursive calls \textit{that we already obtained the result from earlier}.

Dynamic programming fixes this by storing the results of these recursive subcalls in a process called memoization\index{Memoization}. We can simply store a value when we calculate it, so that we can reduce the number of recursive calls done.

\index{Top-Down Dynamic Programming}
\inputcpp{code/dp/fib_dp_td.cpp}

That is called "top-down" dynamic programming because we still make recursive calls, but if we've already gotten the required result from one of our earlier recursive calls we'll store it for any times it appears later.

The alternative is "bottom-up" dynamic programming where we start with the smallest cases and gradually work our way up:

\index{Bottom-Up Dynamic Programming}
\inputcpp{code/dp/fib_dp_bu.cpp}

Here, we don't make any recursive calls at all -- a call of \mintinline{cpp}{fibonacci(10)} will not result in recalculating earlier values in the sequence repeatedly. We start from the base cases, and work our way up from the bottom, hence the term "bottom-up".

You may note that in this problem we can store this permanently, by precalculating entirely:

\index{Precalculation}
\inputcpp{code/dp/fib_precalc.cpp}

Where we call \mintinline{cpp}{genFibonacci()} at the start of the program, and then obtain results from \mintinline{cpp}{fibonacci(n)} or even directly with \mintinline{cpp}{f[n]}.

This works in this specific instance because our stored results are always the same: we always begin with {0,1} and always add the previous two terms. If this might change, whether it be by having different starting numbers or a different number of previous terms (or even coefficients on those terms), we couldn't precalculate beforehand.

In theory, any problem that can be solved recursively can also be solved with dynamic programming. We can simply apply top-down dynamic programming to an existing recursive solution, as long as our recursive function doesn't have any side-effects like printing or modifying a global state. But we don't necessarily see any benefit from doing this -- if there's no overlap in our recursive calls, there's no benefit to storing results.

\subsection{Coin Change}
\index{Coin Change}

Something of interest is that we can also use dynamic programming to efficiently count the number of valid solutions for a given problem.

An example of this will be in the coin change problem. Let's say we have a target value $100$ and a list of elements $10,25,90$, and we want to count how many different ways we can make change from $100$ evenly using the elements of our array. In this variant, we have an infinite amount of each element (so that we can reuse the same values repeatedly). It should be pretty easy to determine the valid solutions, $\{10,90\}$, $\{10,10,10,10,10,25,25\}$, $\{25,25,25,25\}$, and $\{10,10,10,10,10,10,10,10,10,10\}$. Therefore, the count of different ways to make change from $100$ evenly is $4$.

What do we do when our list of valid coins is $\{1,2,3,4,5,6,7,8,9,10,17,25,90\}$? It should be clear that this would be difficult to do naively -- $100$ $1$s is a valid solution, $98$ $1$s and a $2$ is a valid solution, $97$ $1$s and a $3$ is a valid solution, $96$ $1$s and a $4$ or $2$ $2$s are both valid solutions, something like $90$ $1$s and any of $\{10\},\allowbreak\{8,2\},\allowbreak\{7,3\},\allowbreak\{6,4\},\allowbreak\{5,5\},\allowbreak\{6,2,2\},\allowbreak\{5,3,2\},\allowbreak\{4,4,2\},\allowbreak\{4,2,2,2\},\allowbreak\{3,3,2,2\},\allowbreak\{2,2,2,2,2\}$ are all valid solutions. It is far too difficult to simply look at the problem and be able to accurately determine the proper number of valid solutions (in this case, that number is $9505074$).

\inputcpp{code/dp/coinchange.cpp}

\subsection{Longest Common Subsequence}
\index{Longest Common Subsequence}

The Longest Common Subsequence problem (commonly called the LCS problem) is one where you're given two strings (or some other array of data) and, as the name suggests, you have to find the longest subsequence they have in common.

Recall that subsequences refer to a sequence with some elements deleted from the original (including no elements or all elements), so that there is (potentially) less elements but they are all from the original sequence and keep the original ordering. For example, with the string "abcdef", some valid subsequences would be "abc" or "ace", or even the original string "abcdef" or an empty string "".

A subsequence in common, therefore, would be any subsequence that exists in two different sequences at once. Given two strings "abcdef" and "defghi", they might contain the common subsequences \{"", "d", "e", "f", "de", "ef", "def"\}. As another example, the common subsequences of "abcdef" and "aceg" would be \{"", "a", "c", "e", "ac", "ce", "ace"\}. It should be clear what the longest common subsequence is with these examples, "def" and "ace" respectively.

A potential problem that we may have to deal with is that the first possible subsequence we can take isn't necessarily the best one. In the above examples, you might notice that simply adding all letters they have in common would give you the right answers in those testcases. This is not true for all possible strings, for example with "abcde" and "abdbce" if we took a greedy approach we would likely find "abd" when the longest common subsequence is actually "abce".

We can solve this with dynamic programming:

\inputcpp{code/dp/lcs.cpp}

\subsection{Longest Increasing Subsequence}
\index{Longest Increasing Subsequence}

A similar (but also standard) problem as above, we want to deal with the longest subsequence of a single array where all elements are increasing. The main variants of this problem are whether the elements are strictly increasing or not -- for this description we will go with strictly increasing.

As a simple example, if we're given the array $\{1,5,6,2,3,4,7\}$ then the longest increasing subsequence is $\{1,2,3,4,7\}$.

There's a few important observations we can make:
\begin{itemize}
\item Every element always exists within some increasing subsequence, even if it's just itself. For example, in a decreasing array like $\{5,4,3,2,1\}$, every increasing subsequence is $\{5\},\{4\},\{3\},\{2\},\{1\}$. As such, our longest increasing subsequence will always exist and it'll always be at least 1.
\item The next element in the longest increasing subsequence isn't necessarily the next increasing value. For example, consider the array $\{1,4,2,3,4,5\}$. If we greedily take the first element that's increasing, we will get $\{1,4,5\}$ as our subsequence. This is suboptimal, since $\{1,2,3,4,5\}$ is the actual longest subsequence in this case.
\item The next element in the longest increasing subsequence isn't necessarily the next smallest value, either. Consider $\{1,3,4,5,2\}$, greedily taking the next smallest element will get us the subsequence $\{1,2\}$. The correct answer in this case is $\{1,3,4,5\}$.
\end{itemize}

Considering the above, our solution can't be greedy -- we would need to account for the optimal solution involving elements that may not be immediately obvious to a greedy solution.

As for how to actually solve this, we can explore a bottom-up approach. In our memoization table, every element $memo[i]$ contains the length of the longest increasing subsequence in the subarray in the range $[0,i]$ that includes $arr[i]$. The approach to finding this requires us to look at the longest increasing subsequences of our earlier elements: we iterate through the range $[0,i)$ with $j$, and then find the maximum value of $memo[j]$ where $arr[i] > arr[j]$, and set $memo[i] = memo[j] + 1$. In other words, we want to find the longest increasing subsequence that we can append $arr[i]$ to. If there are no existing longest increasing subsequences that $arr[i]$ can be appended to, we simply set $memo[i] = 1$ as a base case.

When we finish our entire array in this fashion, our answer for the longest increasing subsequence is the maximum value of our memoization table.

\inputcpp{code/dp/lis.cpp}

\subsection{Problems}

\input{problems/dynamic_fitness/description}

\hrulefill

\input{problems/common_combo/description}

\hrulefill